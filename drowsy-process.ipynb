{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/vovanquangnbk/drowsy-process?scriptVersionId=144340588\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"## Setup","metadata":{}},{"cell_type":"code","source":"!pip -q install facenet-pytorch\n!pip -q install mediapipe","metadata":{"execution":{"iopub.status.busy":"2023-09-20T13:45:58.683485Z","iopub.execute_input":"2023-09-20T13:45:58.684189Z","iopub.status.idle":"2023-09-20T13:46:25.974723Z","shell.execute_reply.started":"2023-09-20T13:45:58.684154Z","shell.execute_reply":"2023-09-20T13:46:25.973321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport pickle\nimport gc\nimport json\nimport glob\nimport time\nimport threading\nimport queue\nimport itertools\nimport pandas as pd\nimport numpy as np\nimport math\nfrom tqdm import tqdm\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\n\n# Image library\nimport cv2\nimport torchvision\nfrom torchvision import transforms\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\n# Model\nfrom facenet_pytorch import MTCNN, InceptionResnetV1, extract_face\nimport mediapipe as mp","metadata":{"execution":{"iopub.status.busy":"2023-09-20T13:46:25.977356Z","iopub.execute_input":"2023-09-20T13:46:25.977826Z","iopub.status.idle":"2023-09-20T13:46:39.074489Z","shell.execute_reply.started":"2023-09-20T13:46:25.977784Z","shell.execute_reply":"2023-09-20T13:46:39.073465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(f'Running on device: {device}')","metadata":{"execution":{"iopub.status.busy":"2023-09-20T13:46:39.075814Z","iopub.execute_input":"2023-09-20T13:46:39.077035Z","iopub.status.idle":"2023-09-20T13:46:39.083114Z","shell.execute_reply.started":"2023-09-20T13:46:39.076996Z","shell.execute_reply":"2023-09-20T13:46:39.081936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dir = '/kaggle/input/sust-ddd/SUST Driver Drowsiness Dataset'\nmeta_dir = '/kaggle/input/sust-ddd-metadata/dataset_metadata.json'","metadata":{"execution":{"iopub.status.busy":"2023-09-20T13:46:39.085831Z","iopub.execute_input":"2023-09-20T13:46:39.086227Z","iopub.status.idle":"2023-09-20T13:46:39.100197Z","shell.execute_reply.started":"2023-09-20T13:46:39.086202Z","shell.execute_reply":"2023-09-20T13:46:39.09922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CFG = {\n    'vectorize': False,\n    'extract_face': False,\n    'extract_keypoints': True,\n    'batch_size': 60,\n    'show_examples': False,\n    'n_frames': 3,\n    'face_shape': (160,160),\n}","metadata":{"execution":{"iopub.status.busy":"2023-09-20T13:46:39.101165Z","iopub.execute_input":"2023-09-20T13:46:39.101842Z","iopub.status.idle":"2023-09-20T13:46:39.111212Z","shell.execute_reply.started":"2023-09-20T13:46:39.101812Z","shell.execute_reply":"2023-09-20T13:46:39.110572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create CSV","metadata":{}},{"cell_type":"markdown","source":"Process metadata file so we can map video_id with fold","metadata":{}},{"cell_type":"code","source":"f = open(meta_dir)\nmetadata_org = json.load(f)\nf.close\n\nmetadata = {}\nfor fold in metadata_org.keys():\n    for class_name, vd_ids in metadata_org[fold].items():\n        for idx in vd_ids:\n            metadata[idx] = fold","metadata":{"execution":{"iopub.status.busy":"2023-09-20T13:46:39.112218Z","iopub.execute_input":"2023-09-20T13:46:39.112651Z","iopub.status.idle":"2023-09-20T13:46:39.1285Z","shell.execute_reply.started":"2023-09-20T13:46:39.112625Z","shell.execute_reply":"2023-09-20T13:46:39.127672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Helper dicts","metadata":{}},{"cell_type":"code","source":"int2label = {\n    1: \"drowsiness\",\n    0: \"not drowsiness\"\n}\nlabel2int = {v:k for k,v in int2label.items()}","metadata":{"execution":{"iopub.status.busy":"2023-09-20T13:46:39.129779Z","iopub.execute_input":"2023-09-20T13:46:39.130047Z","iopub.status.idle":"2023-09-20T13:46:39.134539Z","shell.execute_reply.started":"2023-09-20T13:46:39.130024Z","shell.execute_reply":"2023-09-20T13:46:39.133574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Main function","metadata":{}},{"cell_type":"code","source":"def create_csv(data_dir, label2int):\n    \"\"\"\n    Input: data_dir\n    - dir format: data_dir/class/img_file\n    Output: csv\n    \"\"\"\n    df = {'id': [], 'label': [], 'label_name':[], 'path':[]}\n    for folder in glob.glob(data_dir + '/*'):\n        # Extract label\n        label_name = folder[folder.rfind(\"/\")+1:]\n\n        # Extract file path\n        f_path = os.path.join(data_dir, folder)\n\n        # Fill in df\n        for f in glob.glob(f_path + '/*'):\n            f_name = f[f.rfind(\"/\")+1:]\n            df['id'].append(f_name)\n            df['label'].append(label2int[label_name])\n            df['label_name'].append(label_name)\n            df['path'].append(f)\n\n    df = pd.DataFrame(df)\n    df = df.dropna()\n    return df\n\ndf = create_csv(data_dir, label2int)\ndf['fold'] = df['id'].replace(metadata)\ndf = df.drop_duplicates()\ndf","metadata":{"execution":{"iopub.status.busy":"2023-09-20T13:46:39.135872Z","iopub.execute_input":"2023-09-20T13:46:39.136137Z","iopub.status.idle":"2023-09-20T13:46:40.578038Z","shell.execute_reply.started":"2023-09-20T13:46:39.136114Z","shell.execute_reply":"2023-09-20T13:46:40.576108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Extract faces","metadata":{}},{"cell_type":"markdown","source":"#### FastMTCNN","metadata":{}},{"cell_type":"code","source":"class FastMTCNN(object):\n    \"\"\"Fast MTCNN implementation.\"\"\"\n    \n    def __init__(self, stride, resize=1, *args, **kwargs):\n        \"\"\"Constructor for FastMTCNN class.\n        \n        Arguments:\n            stride (int): The detection stride. Faces will be detected every `stride` frames\n                and remembered for `stride-1` frames.\n        \n        Keyword arguments:\n            resize (float): Fractional frame scaling. [default: {1}]\n            *args: Arguments to pass to the MTCNN constructor. See help(MTCNN).\n            **kwargs: Keyword arguments to pass to the MTCNN constructor. See help(MTCNN).\n        \"\"\"\n        self.stride = stride\n        self.resize = resize\n        self.mtcnn = MTCNN(*args, **kwargs)\n        \n    def __call__(self, frames):\n        \"\"\"Detect faces in frames using strided MTCNN.\"\"\"\n        if self.resize != 1:\n            frames = [\n                cv2.resize(f, (int(f.shape[1] * self.resize), int(f.shape[0] * self.resize)))\n                    for f in frames\n            ]\n                      \n        boxes, probs = self.mtcnn.detect(frames[::self.stride])\n\n        faces = []\n        for i, frame in enumerate(frames):\n            box_ind = int(i / self.stride)\n            if boxes[box_ind] is None:\n                continue\n            for box in boxes[box_ind]:\n                box = [int(b) for b in box]\n                face = frame[box[1]:box[3], box[0]:box[2]]\n                try:\n                    faces.append(cv2.resize(face, CFG['face_shape'], interpolation = cv2.INTER_AREA))\n                except:\n                    continue\n        \n        return faces","metadata":{"execution":{"iopub.status.busy":"2023-09-20T13:46:40.579417Z","iopub.execute_input":"2023-09-20T13:46:40.580366Z","iopub.status.idle":"2023-09-20T13:46:40.589159Z","shell.execute_reply.started":"2023-09-20T13:46:40.580322Z","shell.execute_reply":"2023-09-20T13:46:40.588185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fast_mtcnn = FastMTCNN(\n    stride=4,\n    resize=0.5,\n    margin=14,\n    factor=0.6,\n    keep_all=True,\n    device=device\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-20T13:46:40.59159Z","iopub.execute_input":"2023-09-20T13:46:40.591891Z","iopub.status.idle":"2023-09-20T13:46:40.682675Z","shell.execute_reply.started":"2023-09-20T13:46:40.591866Z","shell.execute_reply":"2023-09-20T13:46:40.681782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test FastMTCNN\nif CFG['show_examples']:\n    idx = 25\n    v_dir = df.iloc[idx]['path']\n    v_cap = cv2.VideoCapture(v_dir)\n    success = v_cap.grab()        \n    v_len = int(v_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n    fnos = list(range(0, v_len, CFG['n_frames']))\n\n    # set initial frame \n    v_cap.set(cv2.CAP_PROP_POS_FRAMES, fnos[0])\n\n    idx, count = 0, fnos[0]\n    while success:\n        if count == fnos[idx]:\n            success, frame = v_cap.retrieve()\n            if not success:               \n                break\n            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n            face = fast_mtcnn(np.expand_dims(frame,0))[0]\n            plt.figure()\n            plt.imshow(face)\n            plt.show()\n            \n            idx += 1\n            if idx >= len(fnos):\n                break\n        count += 1\n        success = v_cap.grab()\n    v_cap.release()","metadata":{"execution":{"iopub.status.busy":"2023-09-20T13:46:40.684019Z","iopub.execute_input":"2023-09-20T13:46:40.684751Z","iopub.status.idle":"2023-09-20T13:46:40.692467Z","shell.execute_reply.started":"2023-09-20T13:46:40.684719Z","shell.execute_reply":"2023-09-20T13:46:40.691253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Face Vectorizer","metadata":{}},{"cell_type":"code","source":"resnet = InceptionResnetV1(pretrained='vggface2', classify=True).to(device).eval()","metadata":{"execution":{"iopub.status.busy":"2023-09-20T13:46:40.693723Z","iopub.execute_input":"2023-09-20T13:46:40.694046Z","iopub.status.idle":"2023-09-20T13:46:44.932948Z","shell.execute_reply.started":"2023-09-20T13:46:40.694004Z","shell.execute_reply":"2023-09-20T13:46:44.931894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class FaceVectorizer:\n    def __init__(self, detector, n_frames=None, batch_size=None, resize=None):\n        self.detector = detector\n        self.n_frames = n_frames\n        self.batch_size = batch_size\n        self.resize = resize\n    \n    def __call__(self, v_dir):\n        v_cap = cv2.VideoCapture(v_dir)\n        success = v_cap.grab()        \n        v_len = int(v_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n        fnos = list(range(0, v_len, self.n_frames))\n        frames = []\n        faces = []\n\n        # set initial frame \n        v_cap.set(cv2.CAP_PROP_POS_FRAMES, fnos[0])\n\n        idx, count = 0, fnos[0]\n        while success:\n            if count == fnos[idx]:\n                success, frame = v_cap.retrieve()\n                if not success:               \n                    break\n                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n                frames.append(frame)\n                idx += 1\n                if (len(frames) >= self.batch_size) or (idx >= len(fnos)):\n                    faces.extend(self.detector(frames))\n                    frames = []\n\n                if idx >= len(fnos):\n                    break\n            count += 1\n            success = v_cap.grab()\n        v_cap.release()\n        return faces\n    \ndef process_face(faces, vectorizer):\n    # Filter out frames without faces\n    faces = [torch.from_numpy(f).float().permute(2,0,1) for f in faces if f is not None]\n    faces = torch.stack(faces).to(device)\n\n    # Generate facial feature vectors using a pretrained model\n    embeddings = vectorizer(faces).detach().cpu().numpy()\n\n    return embeddings","metadata":{"execution":{"iopub.status.busy":"2023-09-20T13:46:44.934453Z","iopub.execute_input":"2023-09-20T13:46:44.935204Z","iopub.status.idle":"2023-09-20T13:46:44.945145Z","shell.execute_reply.started":"2023-09-20T13:46:44.935175Z","shell.execute_reply":"2023-09-20T13:46:44.944085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Extract facial landmarks","metadata":{}},{"cell_type":"code","source":"mp_face_mesh = mp.solutions.face_mesh\nface_mesh = mp_face_mesh.FaceMesh(\n    static_image_mode=True,\n    max_num_faces=1,\n    refine_landmarks=True,\n    min_detection_confidence=0.5\n)\n\n# LEFT_EYE: 384, 385, 386, 387, 388, 390, 263, 362, 398, 466, 373, 374, 249, 380, 381, 382\n# RIGHT_EYE: 160, 33, 161, 163, 133, 7, 173, 144, 145, 246, 153, 154, 155, 157, 158, 159\n\nLEFT_EYE_INDEXES = list(set(itertools.chain(*mp_face_mesh.FACEMESH_LEFT_EYE)))\nRIGHT_EYE_INDEXES = list(set(itertools.chain(*mp_face_mesh.FACEMESH_RIGHT_EYE)))             \n    \ndef extract_eye_keypoints(frame):    \n    left_eye_pts = []\n    right_eye_pts = []\n\n    face_mesh_results = face_mesh.process(frame)\n    if face_mesh_results.multi_face_landmarks:\n        for face_landmarks in face_mesh_results.multi_face_landmarks:\n            for LEFT_EYE_INDEX in LEFT_EYE_INDEXES:\n                eye_x = face_landmarks.landmark[LEFT_EYE_INDEX].x \n                eye_y = face_landmarks.landmark[LEFT_EYE_INDEX].y \n                left_eye_pts.append((eye_x, eye_y))\n\n            for RIGHT_EYE_INDEX in RIGHT_EYE_INDEXES:\n                eye_x = face_landmarks.landmark[RIGHT_EYE_INDEX].x\n                eye_y = face_landmarks.landmark[RIGHT_EYE_INDEX].y\n                right_eye_pts.append((eye_x, eye_y))\n    return left_eye_pts, right_eye_pts\n\nclass EyeKeypoints:\n    def __init__(self, n_frames=None):\n        self.n_frames = n_frames\n    \n    def __call__(self, v_dir):\n        v_cap = cv2.VideoCapture(v_dir)\n        success = v_cap.grab()        \n        v_len = int(v_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n        fnos = list(range(0, v_len, self.n_frames))\n        eye_pts = []\n\n        # set initial frame \n        v_cap.set(cv2.CAP_PROP_POS_FRAMES, fnos[0])\n\n        idx, count = 0, fnos[0]\n        while success:\n            if count == fnos[idx]:\n                success, frame = v_cap.retrieve()\n                if not success:               \n                    break\n                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n                left_eye_pts, right_eye_pts = extract_eye_keypoints(frame)\n                if left_eye_pts and right_eye_pts:\n                    left_eye_pts = np.array(left_eye_pts)\n                    right_eye_pts = np.array(right_eye_pts)\n                    eye_pts.append(np.concatenate((left_eye_pts, right_eye_pts), axis=1))\n                \n                idx += 1\n                if idx >= len(fnos):\n                    break\n            count += 1\n            success = v_cap.grab()\n        v_cap.release()\n        if eye_pts:\n            return np.stack(eye_pts, axis=0)\n        else:\n            return None","metadata":{"execution":{"iopub.status.busy":"2023-09-20T13:54:39.587715Z","iopub.execute_input":"2023-09-20T13:54:39.58809Z","iopub.status.idle":"2023-09-20T13:54:39.61103Z","shell.execute_reply.started":"2023-09-20T13:54:39.588061Z","shell.execute_reply":"2023-09-20T13:54:39.609705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if CFG['show_examples']:\n    idx = 25\n    v_dir = df.iloc[idx]['path']\n    extracter =  EyeKeypoints(\n        n_frames = CFG['n_frames']\n    )\n    eye_pts = extracter(v_dir)\n    print(eye_pts.shape)","metadata":{"execution":{"iopub.status.busy":"2023-09-18T16:43:19.621575Z","iopub.execute_input":"2023-09-18T16:43:19.622361Z","iopub.status.idle":"2023-09-18T16:43:19.629145Z","shell.execute_reply.started":"2023-09-18T16:43:19.622321Z","shell.execute_reply":"2023-09-18T16:43:19.628112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Main","metadata":{}},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"KAGGLE_KEY\")\n\nos.makedirs('/kaggle/dataset/', exist_ok=True)\nos.makedirs('/root/.kaggle/', exist_ok=True)\n    \napi_token = {\"username\":\"vovanquangnbk\",\"key\":\"507e3751d7cd3d60453ea1abe2b9ca9c\"}\n\nwith open('/root/.kaggle/kaggle.json', 'w') as file:\n    json.dump(api_token, file)\n!chmod 600 /root/.kaggle/kaggle.json","metadata":{"execution":{"iopub.status.busy":"2023-09-18T16:43:19.630847Z","iopub.execute_input":"2023-09-18T16:43:19.631634Z","iopub.status.idle":"2023-09-18T16:43:21.009035Z","shell.execute_reply.started":"2023-09-18T16:43:19.631598Z","shell.execute_reply":"2023-09-18T16:43:21.007241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create and write file to dataset folder\nif CFG['vectorize']:\n    face_vectorizer = FaceVectorizer(\n        detector = fast_mtcnn,\n        n_frames = CFG['n_frames'],\n        batch_size = CFG['batch_size'], \n        resize=1\n    )\n\n    folds = np.arange(1,len(df['fold'].unique())+1)\n    for fold in folds:\n        print(f\"Running fold {fold}:\")\n        v_ids = df[df['fold'] == f\"fold{fold}\"].index.tolist()\n        output_metadata = {'id': [], 'label': [], 'label_name':[], 'fold':[]}\n\n        faces = None\n        with torch.no_grad():\n            for _, idx in tqdm(enumerate(v_ids), total=len(v_ids)):\n                try:\n                    v_dir = df.iloc[idx]['path']\n                    faces = face_vectorizer(v_dir)\n                    feats = process_face(faces, resnet)\n\n                    # Save vector\n                    vec_name = f\"{df.iloc[idx]['id'].split('.')[0]}.npy\"\n                    os.makedirs(f\"/kaggle/dataset/fold{fold}\", exist_ok=True)\n                    np.save(os.path.join(f\"/kaggle/dataset/fold{fold}\", vec_name), feats)\n\n                    # Add metadata\n                    output_metadata['id'].append(vec_name)\n                    output_metadata['label'].append(df.iloc[idx]['label'])\n                    output_metadata['label_name'].append(df.iloc[idx]['label_name'])\n                    output_metadata['fold'].append(df.iloc[idx]['fold'])\n\n                except KeyboardInterrupt:\n                    print('\\nStopped.')\n                    break\n\n                except Exception as e:\n                    print(e)\n\n        output_metadata = pd.DataFrame(output_metadata)\n        output_metadata = output_metadata.dropna()\n        output_metadata.to_csv(os.path.join(f\"/kaggle/dataset\", f\"metadata_fold{fold}.csv\"), index=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-18T16:43:21.010999Z","iopub.execute_input":"2023-09-18T16:43:21.01218Z","iopub.status.idle":"2023-09-18T16:43:21.026836Z","shell.execute_reply.started":"2023-09-18T16:43:21.012135Z","shell.execute_reply":"2023-09-18T16:43:21.025576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if CFG['extract_face']:\n    \n    folds = np.arange(1,len(df['fold'].unique())+1)\n    for fold in folds:\n        print(f\"Running fold {fold}:\")\n        v_ids = df[df['fold'] == f\"fold{fold}\"].sample(10).index.tolist()\n        output_metadata = {'id': [], 'label': [], 'label_name':[], 'fold':[]}\n\n        faces = None\n        with torch.no_grad():\n            for _, idx in tqdm(enumerate(v_ids), total=len(v_ids)):\n                try:\n                    v_dir = df.iloc[idx]['path']\n                    faces = face_detector(v_dir)\n                    faces = np.stack(faces)\n\n                    # Save face\n                    face_name = f\"{df.iloc[idx]['id'].split('.')[0]}.npy\"\n                    os.makedirs(f\"/kaggle/dataset/face/fold{fold}\", exist_ok=True)\n                    np.save(os.path.join(f\"/kaggle/dataset/face/fold{fold}\", face_name), faces)\n\n                    # Add metadata\n                    output_metadata['id'].append(face_name)\n                    output_metadata['label'].append(df.iloc[idx]['label'])\n                    output_metadata['label_name'].append(df.iloc[idx]['label_name'])\n                    output_metadata['fold'].append(df.iloc[idx]['fold'])\n\n                except KeyboardInterrupt:\n                    print('\\nStopped.')\n                    break\n\n                except Exception as e:\n                    print(e)\n\n        output_metadata = pd.DataFrame(output_metadata)\n        output_metadata = output_metadata.dropna()\n        output_metadata.to_csv(os.path.join(f\"/kaggle/dataset/face\", f\"metadata_fold{fold}.csv\"), index=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-18T16:43:21.028532Z","iopub.execute_input":"2023-09-18T16:43:21.029895Z","iopub.status.idle":"2023-09-18T16:43:21.047898Z","shell.execute_reply.started":"2023-09-18T16:43:21.029854Z","shell.execute_reply":"2023-09-18T16:43:21.047009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Extract eye keypoints\nif CFG['extract_keypoints']:\n    # Save data to Kaggle dataset\n    meta = dict(\n        id=\"vovanquangnbk/drowsy-eye-keypoints\",\n        title=\"My brand new dataset\",\n        isPrivate=True,\n        licenses=[dict(name=\"other\")]\n    )\n\n    with open('/kaggle/dataset/dataset-metadata.json', 'w') as f:\n        json.dump(meta, f)\n        \n    # Run main\n    extracter =  EyeKeypoints(n_frames = CFG['n_frames'])\n    \n    folds = np.arange(1,len(df['fold'].unique())+1)\n    \n    for fold in folds:\n        os.makedirs(f\"/kaggle/dataset/my_dataset/fold{fold}\", exist_ok=True)\n        print(f\"Running fold {fold}:\")\n        v_ids = df[df['fold'] == f\"fold{fold}\"].index.tolist()\n        output_metadata = {'id': [], 'label': [], 'label_name':[], 'fold':[]}\n\n        eye_pts = None\n        for _, idx in tqdm(enumerate(v_ids), total=len(v_ids)):\n            try:\n                v_dir = df.iloc[idx]['path']\n                eye_pts = extracter(v_dir)\n\n                # Save file\n                f_name = f\"{df.iloc[idx]['id'].split('.')[0]}.npy\"\n                np.save(os.path.join(f\"/kaggle/dataset/my_dataset/fold{fold}\", f_name), eye_pts)\n                \n                # Free up RAM\n                del eye_pts\n                gc.collect()\n                \n                # Add metadata\n                output_metadata['id'].append(f_name)\n                output_metadata['label'].append(df.iloc[idx]['label'])\n                output_metadata['label_name'].append(df.iloc[idx]['label_name'])\n                output_metadata['fold'].append(df.iloc[idx]['fold'])\n\n            except KeyboardInterrupt:\n                print('\\nStopped.')\n                break\n\n            except Exception as e:\n                print(e)\n\n        output_metadata = pd.DataFrame(output_metadata)\n        output_metadata = output_metadata.dropna()\n        output_metadata.to_csv(os.path.join(f\"/kaggle/dataset/my_dataset\", f\"metadata_fold{fold}.csv\"), index=False)\n        gc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-09-18T16:43:21.049459Z","iopub.execute_input":"2023-09-18T16:43:21.050392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !kaggle datasets create -p \"/kaggle/dataset\" --dir-mode zip\n!kaggle datasets version -p \"/kaggle/dataset\" -m \"Updated via notebook\" --dir-mode zip","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}